{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('/Users/dan/Code/LLM/llm_analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_analyst.core.research_state import ResearchState\n",
    "research_state = ResearchState()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_analyst.core.config import Config\n",
    "try:\n",
    "    config = Config()\n",
    "    print(config)\n",
    "except Exception as e:\n",
    "    print(f\"Error {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_analyst.document.document import DocumentLoader\n",
    "\n",
    "local_doc_dir=\"/Users/dan/Downloads/amy_papers\"\n",
    "document_loader = DocumentLoader(local_doc_dir)\n",
    "docs = await document_loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_analyst.core.config import Config\n",
    "from llm_analyst.core.research_editor import LLMEditor\n",
    "from llm_analyst.core.research_analyst import LLMAnalyst\n",
    "from llm_analyst.core.research_writer import LLMWriter\n",
    "from llm_analyst.core.research_publisher import LLMPublisher\n",
    "from llm_analyst.core.prompts import Prompts\n",
    "from datetime import datetime, timezone\n",
    "query = \"What happened in the latest burning man floods?\"\n",
    "config_params = {}\n",
    "config_params = {\n",
    "    \"internet_search\" :{\"default_val\":\"ddg_search\"},\n",
    "    \"llm_provider\"    :{\"default_val\":\"openai\"},\n",
    "    \"llm_model\"       :{\"default_val\":\"gpt-4o-2024-05-13\"},\n",
    "}\n",
    "\n",
    "#    \"llm_model\"       :{\"default_val\":\"mixtral-8x7b-32768\"},\n",
    "#    \"llm_model\"       :{\"default_val\":\"gemma-7b-it\"},\n",
    "#    \"llm_model\"       :{\"default_val\":\"llama3-8b-8192\"},\n",
    "#    \"llm_model\"       :{\"default_val\":\"llama3-70b-8192\"},\n",
    "#    \"llm_model\"       :{\"default_val\":\"gpt-4o-2024-05-13\"},\n",
    "\n",
    "\n",
    "config = Config()\n",
    "config._set_values_for_config(config_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_editor = LLMEditor(query, config = config)\n",
    "detailed_report_state = await llm_editor.create_detailed_report()\n",
    "print(detailed_report_state.final_report_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await LLMPublisher.init(detailed_report_state).publish_to_pdf_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm_analyst = LLMAnalyst(query,config = config)\n",
    "primary_research = choose_agent_dict = await llm_analyst.conduct_research()\n",
    "print(\"=\"*40)\n",
    "print(primary_research)\n",
    "subtopics = await llm_analyst.select_subtopics()\n",
    "print(\"=\"*40)\n",
    "print(subtopics)\n",
    "report_state = await llm_analyst.write_report()\n",
    "print(\"=\"*40)\n",
    "print(report_state.report_md)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_analyst.core.research_writer import LLMWriter\n",
    "\n",
    "subtopic_reports = []\n",
    "subtopics_report_body = \"\"\n",
    "\n",
    "for subtopic in subtopics:\n",
    "    print(f\"Researching {subtopic}\")\n",
    "    subtopic_assistant = LLMAnalyst(\n",
    "        active_research_topic = subtopic,\n",
    "        report_type = \"subtopic_report\",\n",
    "        main_research_topic = primary_research.active_research_topic,\n",
    "        visited_urls = primary_research.visited_urls,\n",
    "        agents_role_prompt =  primary_research.agents_role_prompt,\n",
    "        agent_type = primary_research.agent_type\n",
    "    )\n",
    "    subtopic_assistant.research_findings = primary_research.research_findings\n",
    "    subtopic_assistant.report_headings = primary_research.report_headings\n",
    "     \n",
    "    subtopic_research = await subtopic_assistant.conduct_research()\n",
    "    print(f\"Writing {subtopic}\")\n",
    "    subtopic_report = await subtopic_assistant.write_report()\n",
    "\n",
    "    primary_research.research_findings = subtopic_assistant.research_findings\n",
    "    primary_research.visited_urls.update(subtopic_assistant.visited_urls)\n",
    "    primary_research.report_headings.append(\n",
    "        {\n",
    "            \"subtopic task\": subtopic_assistant.active_research_topic,\n",
    "            \"headers\": LLMWriter.init(subtopic_report).extract_headers()\n",
    "        }\n",
    "    )\n",
    "    subtopic_reports.append({ \"topic\": subtopic_assistant.active_research_topic, \"report\": subtopic_report.report_md })\n",
    "    primary_research.report_md += \"\\n\\n\\n\" + subtopic_report.report_md\n",
    "\n",
    "#llm_writer = LLMWriter.init(primary_research)\n",
    "#introduction = await llm_writer.write_introduction()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introduction = await LLMWriter.init(primary_research).write_introduction()\n",
    "print(introduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toc = await LLMWriter.init(primary_research).write_table_of_contents()\n",
    "print(toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "references = LLMWriter.init(primary_research).write_references()\n",
    "print(references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_analyst.core.prompts import Prompts\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "context = \"This context\"\n",
    "question = \"What is the meaning of life?\"\n",
    "total_words = 2000\n",
    "report_format = \"APA\"\n",
    "datetime_now = datetime.now().strftime('%B %d, %Y')\n",
    "\n",
    "prompts = Prompts()\n",
    "prompt = prompts.get_prompt(\"generate_report_prompt\",\n",
    "                            context=context,\n",
    "                            question=question,\n",
    "                            total_words=total_words,\n",
    "                            report_format=report_format,\n",
    "                            datetime_now=datetime_now)\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_analyst.core.prompts import Prompts\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "context = \"This context\"\n",
    "question = \"What is the meaning of life?\"\n",
    "total_words = 2000\n",
    "task = \"What is the meaning of life?\"\n",
    "max_iterations = 5\n",
    "datetime_now = datetime.now().strftime('%B %d, %Y')\n",
    "\n",
    "prompts = Prompts()\n",
    "prompt = prompts.get_prompt(\"generate_resource_report_prompt\",\n",
    "                            context=context,\n",
    "                            question=question,\n",
    "                            total_words=total_words)\n",
    "print(prompt)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llm_analyst.core.prompts import Prompts\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "prompts = Prompts()\n",
    "prompt = prompts.get_prompt(\"auto_agent_instructions\")\n",
    "print(prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "def my_trace_log(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        function_name = inspect.currentframe().f_code.co_name\n",
    "        print(f\"TRACE: Entering {func.__name__}\")\n",
    "        result = func(*args, **kwargs)\n",
    "        print(f\"TRACE: Exiting {func.__name__}\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@my_trace_log\n",
    "def hello_world():\n",
    "    print(\"Hello World\")\n",
    "\n",
    "# Example usage\n",
    "hello_world()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "from llm_analyst.core.exceptions import LLMAnalystsException\n",
    "deterministic_temp=0\n",
    "role = \"You are a well-informed AI news analyst assistant. Your primary goal is to provide comprehensive, accurate, unbiased, and well-structured news reports based on the latest events and developments.\"\n",
    "report_prompt = \"Information: context data....\\n\\nUsing the above information, answer the following query or task: 'What happened in the latest burning man floods?' in a detailed report -- The report should focus on the answer to the query, should be well structured, informative, in-depth and comprehensive, with facts and numbers if available and a minimum of 1000 words.\\nYou should strive to write the report as long as you can using all relevant and necessary information provided.\\nYou must write the report with markdown syntax.\\nUse an unbiased and journalistic tone.\\nYou MUST determine your own concrete and valid opinion based on the given information. Do NOT deter to general and meaningless conclusions.\\nYou MUST write all used source urls at the end of the report as references, and make sure not to add duplicated sources, but only one reference for each.\\nEvery url should be hyperlinked: [url website](url)\\nAdditionally, you MUST include hyperlinks to the relevant URLs wherever they are referenced in the report : \\n\\n       e.g.:\\n            # Report Header\\n\\n            This is a sample text. ([url website](url))\\n\\nYou MUST write the report in APA format.\\nCite search results using inline notations.\\nOnly cite the most relevant results that answer the query accurately.\\nPlace these citations at the end of the sentence or paragraph that reference them.\\nPlease do your best, this is very important to my career.\\nAssume that the current date is May 21, 2024\"\n",
    "messages=[\n",
    "        {\"role\": \"system\", \"content\": \"role\"},\n",
    "        {\"role\": \"user\",   \"content\": \"report_prompt\"}]\n",
    "            \n",
    "#api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "api_key = os.environ[\"GROQ_API_KEY\"]\n",
    "temperature = 0\n",
    "#model = \"gpt-4o-2024-05-13\"\n",
    "model = \"llama3-70b-8192\"\n",
    "max_tokens=4000\n",
    "llm = ChatGroq(\n",
    "            model = model,\n",
    "            temperature = temperature,\n",
    "            max_tokens = max_tokens,\n",
    "            api_key = api_key\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_params = {}\n",
    "config_params = {\n",
    "    \"internet_search\" :{\"default_val\":\"ddg_search\"},\n",
    "    \"llm_provider\"    :{\"default_val\":\"groq\"},\n",
    "    \"llm_model\"       :{\"default_val\":\"llama3-8b-8192\"},\n",
    "}\n",
    "\n",
    "config = Config()\n",
    "config._set_values_for_config(config_params)\n",
    "llm_analyst = LLMAnalyst(query,config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_state = llm_analyst.get_research_state()\n",
    "research_state.report_md=\"Test\"\n",
    "print(research_state)\n",
    "print(llm_analyst.cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_writer = LLMWriter.init(research_state)\n",
    "print(llm_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_str = \"\"\n",
    "\n",
    "if not empty_str:\n",
    "    print(\"The string is empty.\")\n",
    "else:\n",
    "    print(\"The string is not empty.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_analyst.core.research_state import ResearchState\n",
    "research_state = ResearchState(active_research_topic = \"Test topic\",\n",
    "                                report_type = \"detailed\",\n",
    "                                agent_type = \"news agent\",\n",
    "                                agents_role_prompt=\"agent role\")\n",
    "\n",
    "\n",
    "research_state.dump(\"reseach_state.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('/Users/dan/Code/LLM/llm_analyst')\n",
    "from llm_analyst.core.research_state import ResearchState\n",
    "loaded = ResearchState.load(\"reseach_state.json\")\n",
    "print(loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "# Replace 'your_api_key_here' with your actual OpenAI API key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {api_key}'\n",
    "}\n",
    "\n",
    "# API endpoint to get usage details\n",
    "url = 'https://api.openai.com/v1/dashboard/billing/usage'\n",
    "\n",
    "# Optional: Specify the date range for the usage data\n",
    "params = {\n",
    "    'start_date': '2024-05-01',\n",
    "    'end_date': '2024-05-31'\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    usage_data = response.json()\n",
    "    print(\"Usage data:\", usage_data)\n",
    "else:\n",
    "    print(f\"Failed to retrieve usage data. Status code: {response.status_code}\")\n",
    "    print(\"Response:\", response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-researcher",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
